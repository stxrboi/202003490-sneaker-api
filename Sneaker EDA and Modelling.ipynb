{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b296a3-6fb4-45ae-967a-e6f91b920cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /users/gary/.local/lib/python3.8/site-packages (23.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2e06be-32f6-4727-a45c-fa5d62ac9d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5947597f-53ed-4790-b3bf-2292c4d25471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /users/gary/.local/lib/python3.8/site-packages (4.33.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /users/gary/.local/lib/python3.8/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /users/gary/.local/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /users/gary/.local/lib/python3.8/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2022.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b3db0c-a112-4a04-a5ab-2ad8aa4c6c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /users/gary/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /users/gary/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /users/gary/nltk_data...\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-30 15:52:03.516058: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from transformers import pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8d27d284-efa9-4306-8f82-6d5cd3b87786",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (100000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>16074</td>\n",
       "      <td>3</td>\n",
       "      <td>Comfortable, but not durable.</td>\n",
       "      <td>2022/11/07 05:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>436</td>\n",
       "      <td>11648</td>\n",
       "      <td>4</td>\n",
       "      <td>Highly recommend!</td>\n",
       "      <td>2021/09/11 02:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>861</td>\n",
       "      <td>46508</td>\n",
       "      <td>2</td>\n",
       "      <td>Do not recommend.</td>\n",
       "      <td>2022/12/14 13:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>271</td>\n",
       "      <td>40094</td>\n",
       "      <td>3</td>\n",
       "      <td>Comfortable, but not durable.</td>\n",
       "      <td>2021/11/29 04:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>49897</td>\n",
       "      <td>4</td>\n",
       "      <td>Will buy again.</td>\n",
       "      <td>2023/04/24 12:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  product_id  user_id  rating                    review_text  \\\n",
       "0          1         103    16074       3  Comfortable, but not durable.   \n",
       "1          2         436    11648       4              Highly recommend!   \n",
       "2          3         861    46508       2              Do not recommend.   \n",
       "3          4         271    40094       3  Comfortable, but not durable.   \n",
       "4          5         107    49897       4                Will buy again.   \n",
       "\n",
       "          timestamp  \n",
       "0  2022/11/07 05:30  \n",
       "1  2021/09/11 02:53  \n",
       "2  2022/12/14 13:24  \n",
       "3  2021/11/29 04:01  \n",
       "4  2023/04/24 12:12  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sneakers_Reviews_Dataset.csv', sep=\";\")\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a24166cd-dbc1-48b4-bc8f-6bf59b9aeb85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df['rating'].value_counts().sort_index() \\\n",
    "    .plot(kind='bar',\n",
    "          title='Count of Reviews by Rating',\n",
    "          figsize=(10, 5))\n",
    "ax.set_xlabel('Review Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "04be41fc-b3cd-40a3-ad54-5948971e5158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    20096\n",
       "2    20066\n",
       "5    20006\n",
       "3    19924\n",
       "1    19908\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "030a94f1-4eb9-4d86-9b60-2330f64a4c24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   review_id    100000 non-null  int64 \n",
      " 1   product_id   100000 non-null  int64 \n",
      " 2   user_id      100000 non-null  int64 \n",
      " 3   rating       100000 non-null  int64 \n",
      " 4   review_text  100000 non-null  object\n",
      " 5   timestamp    100000 non-null  object\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9b2c8b89-eda0-47d6-83de-c89d5b23ff01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id      0\n",
      "product_id     0\n",
      "user_id        0\n",
      "rating         0\n",
      "review_text    0\n",
      "timestamp      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b237c-d6ab-4c41-ac23-134893e6ba68",
   "metadata": {
    "tags": []
   },
   "source": [
    "- No missing values present in the dataset and is fairly balanced as each rating has about +-20000 reviews contributing to the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e049bd69-8ebf-4b4a-a470-16f88552406a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>500.827000</td>\n",
       "      <td>24989.389640</td>\n",
       "      <td>3.002260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28867.657797</td>\n",
       "      <td>288.826213</td>\n",
       "      <td>14417.825247</td>\n",
       "      <td>1.413575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25000.750000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>12481.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50000.500000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>24916.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75000.250000</td>\n",
       "      <td>752.000000</td>\n",
       "      <td>37479.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>49998.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review_id     product_id        user_id         rating\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
       "mean    50000.500000     500.827000   24989.389640       3.002260\n",
       "std     28867.657797     288.826213   14417.825247       1.413575\n",
       "min         1.000000       1.000000       1.000000       1.000000\n",
       "25%     25000.750000     251.000000   12481.750000       2.000000\n",
       "50%     50000.500000     501.000000   24916.000000       3.000000\n",
       "75%     75000.250000     752.000000   37479.250000       4.000000\n",
       "max    100000.000000    1000.000000   49998.000000       5.000000"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7138a050-3b2b-4397-ba35-3b1b22d2ba43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Comfortable, but not durable.', 'Highly recommend!',\n",
       "       'Do not recommend.', 'Will buy again.', 'Very uncomfortable.',\n",
       "       'They are okay.', 'Poor quality!', 'I love these sneakers.',\n",
       "       'Great quality!', 'Waste of money.', 'Very comfortable.',\n",
       "       'Average sneakers.', 'Falling apart after a week.',\n",
       "       'Decent quality.'], dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_text'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fa51ceb4-cd9e-4bf2-95df-60193a4d8a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I love these sneakers.           8111\n",
       "Will buy again.                  8082\n",
       "Do not recommend.                8067\n",
       "Falling apart after a week.      8035\n",
       "Very uncomfortable.              8009\n",
       "Highly recommend!                7984\n",
       "Poor quality!                    7970\n",
       "Great quality!                   7966\n",
       "Very comfortable.                7959\n",
       "Waste of money.                  7893\n",
       "Average sneakers.                5078\n",
       "Decent quality.                  4965\n",
       "Comfortable, but not durable.    4960\n",
       "They are okay.                   4921\n",
       "Name: review_text, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_text'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cd1908-e405-4fdd-9133-024008e28314",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ebe9aacb-acdf-49aa-96d6-586e9c8ff00f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "n = random.randint(0,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "183e6e56-1868-4861-ad27-b04816aa6ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very uncomfortable.\n"
     ]
    }
   ],
   "source": [
    "ex = df['review_text'][n]\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7389f016-3cc8-4b65-a11f-7d948a4c128e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very uncomfortable.\n"
     ]
    }
   ],
   "source": [
    "# convert to lowercase\n",
    "ex = ex.lower()\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d08d6853-1cd8-478c-8f30-e4d22bf9dcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very uncomfortable\n"
     ]
    }
   ],
   "source": [
    "#remove punctuation\n",
    "ex = ex.translate(str.maketrans('', '', string.punctuation))\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a32ab6d4-6523-4446-899f-cf12068e87df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize example text\n",
    "tokens = word_tokenize(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6d52a541-9a7b-4a32-844d-da3c066ee97b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very', 'uncomfortable']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a8c32731-04fa-4657-b9b6-e5c136745142",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'few', 'for', 'whom', \"that'll\", 'above', 'was', 'a', 'with', \"should've\", 'to', 'we', \"you'd\", 'mustn', 'those', 'out', 'won', 'which', 'no', 'before', 'is', \"mustn't\", 'hers', 'own', 'his', 'm', 'himself', 'then', 'itself', 's', 'should', 'once', 'nor', 'haven', 'off', 'at', 'shouldn', 'hasn', 'themselves', 'down', \"won't\", 'our', 'doing', 'they', 'not', 'why', 'll', 'being', 'wouldn', 'from', 'couldn', 'didn', 'very', 'and', 'where', 'her', 'same', 'through', 'do', \"you're\", \"doesn't\", 'again', 'herself', 'each', 'my', 'but', 'further', 'an', 'its', 'yours', 'having', 'while', 'or', 'of', 'during', 'there', 'i', 'that', 'these', 'after', \"aren't\", \"haven't\", 'yourselves', \"needn't\", \"weren't\", \"mightn't\", \"you'll\", 't', 'hadn', 'were', \"wasn't\", 'here', 'aren', 'you', 'below', 'both', \"hasn't\", 'so', \"couldn't\", 'too', 'your', 'about', 'myself', 'isn', 'did', 'than', 'how', 'o', 'if', 'mightn', 'this', 'has', 'other', 'some', 'does', 'ours', 'theirs', 'until', 'in', 'needn', 'doesn', 'more', 'such', 'd', 'shan', \"isn't\", 've', 'him', \"hadn't\", 'what', 'she', 'because', \"shan't\", 'am', 'just', 'any', 'now', 'y', \"don't\", 'by', 'had', 'them', 'up', 'all', \"didn't\", 'ain', \"it's\", 'wasn', \"you've\", 'against', 'their', 'he', 'it', 'are', 'most', 'the', 'over', 'have', 'don', \"she's\", 'under', \"shouldn't\", \"wouldn't\", 'into', 'who', 'ma', 'be', 'on', 'been', 'weren', 'ourselves', 'only', 'when', 'will', 're', 'between', 'me', 'as', 'yourself', 'can'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1919fbd6-cafe-4984-ad9e-d5033d7bf511",
   "metadata": {},
   "source": [
    "- Since the stop words include words such as not and don't which is present in our dataset and can be used to express a negative statement we shall not remove the stop words in hope of a more accurate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "71a46ab2-af9c-4287-a1f5-b0e70ff9d2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very', 'uncomfortable']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "06da81b2-87b0-4be5-8bbb-5cb590f7e26d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "#sentiment = AutoModelForSequenceClassification.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2f1cc81d-a893-4a84-9c42-e1f01df4d006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokens = [lemmatizer.lemmatize(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ee7cffaa-9ea9-4e13-8ec0-c88ac4bee073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very', 'uncomfortable']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0b7b9267-09a9-4a93-b9dd-1cf9cf3104bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join tokens back into a single string\n",
    "combo = ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3c383650-e06c-4845-b6d5-4a2742998db9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very uncomfortable\n"
     ]
    }
   ],
   "source": [
    "print(combo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e728d7-516c-43ad-b603-14cb84308021",
   "metadata": {},
   "source": [
    "Now that everything seems to be functional lets create a function to do it for every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9ae0f487-6dab-448d-b668-0cc52aca3abd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         review_text          cleaned_review_text\n",
      "0      Comfortable, but not durable.  comfortable but not durable\n",
      "1                  Highly recommend!             highly recommend\n",
      "2                  Do not recommend.             do not recommend\n",
      "3      Comfortable, but not durable.  comfortable but not durable\n",
      "4                    Will buy again.               will buy again\n",
      "...                              ...                          ...\n",
      "99995    Falling apart after a week.   falling apart after a week\n",
      "99996              Highly recommend!             highly recommend\n",
      "99997                Will buy again.               will buy again\n",
      "99998                Waste of money.               waste of money\n",
      "99999                Waste of money.               waste of money\n",
      "\n",
      "[100000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply the preprocess_text function to the 'review_text' column\n",
    "df['cleaned_review_text'] = df['review_text'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "# Display the cleaned review_text column\n",
    "print(df[['review_text', 'cleaned_review_text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4f8d4-7f08-4f0d-bad7-de6eaaa67654",
   "metadata": {},
   "source": [
    "We have now pre-processed our text by:\n",
    "- removing punctuation,\n",
    "- lowering all the words received,\n",
    "- lemmatization, i.e., grouping variant forms of a word.\n",
    "\n",
    "Moving onto the next step, we shall focus on feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b16900f-63a4-4763-96a5-1fe5948b09d6",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096fbacf-a229-443e-9d58-e8d69550224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vectorizer = TfidfVectorizer(max_features=1000) \n",
    "#X = tfidf_vectorizer.fit_transform(df['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "420d7840-e3af-47e7-80a9-a5daad6571a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       after    again  apart  are  average       but      buy  comfortable  \\\n",
      "0        0.0  0.00000    0.0  0.0      0.0  0.563004  0.00000     0.428401   \n",
      "1        0.0  0.00000    0.0  0.0      0.0  0.000000  0.00000     0.000000   \n",
      "2        0.0  0.00000    0.0  0.0      0.0  0.000000  0.00000     0.000000   \n",
      "3        0.0  0.00000    0.0  0.0      0.0  0.563004  0.00000     0.428401   \n",
      "4        0.0  0.57735    0.0  0.0      0.0  0.000000  0.57735     0.000000   \n",
      "...      ...      ...    ...  ...      ...       ...      ...          ...   \n",
      "99995    0.5  0.00000    0.5  0.0      0.0  0.000000  0.00000     0.000000   \n",
      "99996    0.0  0.00000    0.0  0.0      0.0  0.000000  0.00000     0.000000   \n",
      "99997    0.0  0.57735    0.0  0.0      0.0  0.000000  0.57735     0.000000   \n",
      "99998    0.0  0.00000    0.0  0.0      0.0  0.000000  0.00000     0.000000   \n",
      "99999    0.0  0.00000    0.0  0.0      0.0  0.000000  0.00000     0.000000   \n",
      "\n",
      "       decent        do  ...  quality  recommend  sneaker  these  they  \\\n",
      "0         0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
      "1         0.0  0.000000  ...      0.0   0.625673      0.0    0.0   0.0   \n",
      "2         0.0  0.646419  ...      0.0   0.519989      0.0    0.0   0.0   \n",
      "3         0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
      "4         0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
      "...       ...       ...  ...      ...        ...      ...    ...   ...   \n",
      "99995     0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
      "99996     0.0  0.000000  ...      0.0   0.625673      0.0    0.0   0.0   \n",
      "99997     0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
      "99998     0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
      "99999     0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
      "\n",
      "       uncomfortable  very    waste  week     will  \n",
      "0                0.0   0.0  0.00000   0.0  0.00000  \n",
      "1                0.0   0.0  0.00000   0.0  0.00000  \n",
      "2                0.0   0.0  0.00000   0.0  0.00000  \n",
      "3                0.0   0.0  0.00000   0.0  0.00000  \n",
      "4                0.0   0.0  0.00000   0.0  0.57735  \n",
      "...              ...   ...      ...   ...      ...  \n",
      "99995            0.0   0.0  0.00000   0.5  0.00000  \n",
      "99996            0.0   0.0  0.00000   0.0  0.00000  \n",
      "99997            0.0   0.0  0.00000   0.0  0.57735  \n",
      "99998            0.0   0.0  0.57735   0.0  0.00000  \n",
      "99999            0.0   0.0  0.57735   0.0  0.00000  \n",
      "\n",
      "[100000 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  \n",
    "\n",
    "# Fit and transform the cleaned review_text\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['cleaned_review_text'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a Pandas DataFrame\n",
    "numeric_review = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# The numeric_review now contains the numerical representations of the cleaned review_text\n",
    "print(numeric_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3cc1e88a-cb48-48d4-b92b-67582ee572da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10)\t0.5630035948074295\n",
      "  (0, 16)\t0.42723078343887516\n",
      "  (0, 5)\t0.5630035948074295\n",
      "  (0, 7)\t0.42840140306729674\n",
      "  (1, 21)\t0.6256727386225173\n",
      "  (1, 13)\t0.7800856518002359\n",
      "  (2, 9)\t0.6464185987229392\n",
      "  (2, 21)\t0.5199885071673452\n",
      "  (2, 16)\t0.5583502016109132\n",
      "  (3, 10)\t0.5630035948074295\n",
      "  (3, 16)\t0.42723078343887516\n",
      "  (3, 5)\t0.5630035948074295\n",
      "  (3, 7)\t0.42840140306729674\n",
      "  (4, 1)\t0.5773502691896257\n",
      "  (4, 6)\t0.5773502691896257\n",
      "  (4, 29)\t0.5773502691896257\n",
      "  (5, 25)\t0.779254973505128\n",
      "  (5, 26)\t0.6267070178859676\n",
      "  (6, 18)\t0.5773502691896257\n",
      "  (6, 3)\t0.5773502691896257\n",
      "  (6, 24)\t0.5773502691896257\n",
      "  (7, 21)\t0.6256727386225173\n",
      "  (7, 13)\t0.7800856518002359\n",
      "  (8, 20)\t0.5879499130172028\n",
      "  (8, 19)\t0.8088973357497623\n",
      "  :\t:\n",
      "  (99990, 29)\t0.5773502691896257\n",
      "  (99991, 26)\t0.6811898633637172\n",
      "  (99991, 7)\t0.7321068023523073\n",
      "  (99992, 20)\t0.5879499130172028\n",
      "  (99992, 19)\t0.8088973357497623\n",
      "  (99993, 9)\t0.6464185987229392\n",
      "  (99993, 21)\t0.5199885071673452\n",
      "  (99993, 16)\t0.5583502016109132\n",
      "  (99994, 26)\t0.6811898633637172\n",
      "  (99994, 7)\t0.7321068023523073\n",
      "  (99995, 28)\t0.5\n",
      "  (99995, 0)\t0.5\n",
      "  (99995, 2)\t0.5\n",
      "  (99995, 11)\t0.5\n",
      "  (99996, 21)\t0.6256727386225173\n",
      "  (99996, 13)\t0.7800856518002359\n",
      "  (99997, 1)\t0.5773502691896257\n",
      "  (99997, 6)\t0.5773502691896257\n",
      "  (99997, 29)\t0.5773502691896257\n",
      "  (99998, 15)\t0.5773502691896257\n",
      "  (99998, 17)\t0.5773502691896257\n",
      "  (99998, 27)\t0.5773502691896257\n",
      "  (99999, 15)\t0.5773502691896257\n",
      "  (99999, 17)\t0.5773502691896257\n",
      "  (99999, 27)\t0.5773502691896257\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "83661426-2192-4533-8aea-319506827c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>apart</th>\n",
       "      <th>are</th>\n",
       "      <th>average</th>\n",
       "      <th>but</th>\n",
       "      <th>buy</th>\n",
       "      <th>comfortable</th>\n",
       "      <th>decent</th>\n",
       "      <th>do</th>\n",
       "      <th>...</th>\n",
       "      <th>quality</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sneaker</th>\n",
       "      <th>these</th>\n",
       "      <th>they</th>\n",
       "      <th>uncomfortable</th>\n",
       "      <th>very</th>\n",
       "      <th>waste</th>\n",
       "      <th>week</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563004</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.428401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.646419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563004</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.428401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       after    again  apart  are  average       but      buy  comfortable  \\\n",
       "0        0.0  0.00000    0.0  0.0      0.0  0.563004  0.00000     0.428401   \n",
       "1        0.0  0.00000    0.0  0.0      0.0  0.000000  0.00000     0.000000   \n",
       "2        0.0  0.00000    0.0  0.0      0.0  0.000000  0.00000     0.000000   \n",
       "3        0.0  0.00000    0.0  0.0      0.0  0.563004  0.00000     0.428401   \n",
       "4        0.0  0.57735    0.0  0.0      0.0  0.000000  0.57735     0.000000   \n",
       "...      ...      ...    ...  ...      ...       ...      ...          ...   \n",
       "99995    0.5  0.00000    0.5  0.0      0.0  0.000000  0.00000     0.000000   \n",
       "99996    0.0  0.00000    0.0  0.0      0.0  0.000000  0.00000     0.000000   \n",
       "99997    0.0  0.57735    0.0  0.0      0.0  0.000000  0.57735     0.000000   \n",
       "99998    0.0  0.00000    0.0  0.0      0.0  0.000000  0.00000     0.000000   \n",
       "99999    0.0  0.00000    0.0  0.0      0.0  0.000000  0.00000     0.000000   \n",
       "\n",
       "       decent        do  ...  quality  recommend  sneaker  these  they  \\\n",
       "0         0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
       "1         0.0  0.000000  ...      0.0   0.625673      0.0    0.0   0.0   \n",
       "2         0.0  0.646419  ...      0.0   0.519989      0.0    0.0   0.0   \n",
       "3         0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
       "4         0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
       "...       ...       ...  ...      ...        ...      ...    ...   ...   \n",
       "99995     0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
       "99996     0.0  0.000000  ...      0.0   0.625673      0.0    0.0   0.0   \n",
       "99997     0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
       "99998     0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
       "99999     0.0  0.000000  ...      0.0   0.000000      0.0    0.0   0.0   \n",
       "\n",
       "       uncomfortable  very    waste  week     will  \n",
       "0                0.0   0.0  0.00000   0.0  0.00000  \n",
       "1                0.0   0.0  0.00000   0.0  0.00000  \n",
       "2                0.0   0.0  0.00000   0.0  0.00000  \n",
       "3                0.0   0.0  0.00000   0.0  0.00000  \n",
       "4                0.0   0.0  0.00000   0.0  0.57735  \n",
       "...              ...   ...      ...   ...      ...  \n",
       "99995            0.0   0.0  0.00000   0.5  0.00000  \n",
       "99996            0.0   0.0  0.00000   0.0  0.00000  \n",
       "99997            0.0   0.0  0.00000   0.0  0.57735  \n",
       "99998            0.0   0.0  0.57735   0.0  0.00000  \n",
       "99999            0.0   0.0  0.57735   0.0  0.00000  \n",
       "\n",
       "[100000 rows x 30 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d70ef42b-51dd-4f1d-8b9c-a69b120d45b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = pd.concat([df, numeric_review], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a006d749-1f2f-4b60-92ba-acdc41d543cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>apart</th>\n",
       "      <th>...</th>\n",
       "      <th>quality</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sneaker</th>\n",
       "      <th>these</th>\n",
       "      <th>they</th>\n",
       "      <th>uncomfortable</th>\n",
       "      <th>very</th>\n",
       "      <th>waste</th>\n",
       "      <th>week</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>16074</td>\n",
       "      <td>3</td>\n",
       "      <td>Comfortable, but not durable.</td>\n",
       "      <td>2022/11/07 05:30</td>\n",
       "      <td>comfortable but not durable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>436</td>\n",
       "      <td>11648</td>\n",
       "      <td>4</td>\n",
       "      <td>Highly recommend!</td>\n",
       "      <td>2021/09/11 02:53</td>\n",
       "      <td>highly recommend</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>861</td>\n",
       "      <td>46508</td>\n",
       "      <td>2</td>\n",
       "      <td>Do not recommend.</td>\n",
       "      <td>2022/12/14 13:24</td>\n",
       "      <td>do not recommend</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>271</td>\n",
       "      <td>40094</td>\n",
       "      <td>3</td>\n",
       "      <td>Comfortable, but not durable.</td>\n",
       "      <td>2021/11/29 04:01</td>\n",
       "      <td>comfortable but not durable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>49897</td>\n",
       "      <td>4</td>\n",
       "      <td>Will buy again.</td>\n",
       "      <td>2023/04/24 12:12</td>\n",
       "      <td>will buy again</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  product_id  user_id  rating                    review_text  \\\n",
       "0          1         103    16074       3  Comfortable, but not durable.   \n",
       "1          2         436    11648       4              Highly recommend!   \n",
       "2          3         861    46508       2              Do not recommend.   \n",
       "3          4         271    40094       3  Comfortable, but not durable.   \n",
       "4          5         107    49897       4                Will buy again.   \n",
       "\n",
       "          timestamp          cleaned_review_text  after    again  apart  ...  \\\n",
       "0  2022/11/07 05:30  comfortable but not durable    0.0  0.00000    0.0  ...   \n",
       "1  2021/09/11 02:53             highly recommend    0.0  0.00000    0.0  ...   \n",
       "2  2022/12/14 13:24             do not recommend    0.0  0.00000    0.0  ...   \n",
       "3  2021/11/29 04:01  comfortable but not durable    0.0  0.00000    0.0  ...   \n",
       "4  2023/04/24 12:12               will buy again    0.0  0.57735    0.0  ...   \n",
       "\n",
       "   quality  recommend  sneaker  these  they  uncomfortable  very  waste  week  \\\n",
       "0      0.0   0.000000      0.0    0.0   0.0            0.0   0.0    0.0   0.0   \n",
       "1      0.0   0.625673      0.0    0.0   0.0            0.0   0.0    0.0   0.0   \n",
       "2      0.0   0.519989      0.0    0.0   0.0            0.0   0.0    0.0   0.0   \n",
       "3      0.0   0.000000      0.0    0.0   0.0            0.0   0.0    0.0   0.0   \n",
       "4      0.0   0.000000      0.0    0.0   0.0            0.0   0.0    0.0   0.0   \n",
       "\n",
       "      will  \n",
       "0  0.00000  \n",
       "1  0.00000  \n",
       "2  0.00000  \n",
       "3  0.00000  \n",
       "4  0.57735  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea366f71-b0ba-4506-9798-bb269239b83a",
   "metadata": {},
   "source": [
    "### Label Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4f8dd2f0-2999-426b-8387-c50cbf79bb17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rating sentiment\n",
      "0           3   Neutral\n",
      "1           4  Positive\n",
      "2           2   Neutral\n",
      "3           3   Neutral\n",
      "4           4  Positive\n",
      "...       ...       ...\n",
      "99995       1  Negative\n",
      "99996       5  Positive\n",
      "99997       5  Positive\n",
      "99998       1  Negative\n",
      "99999       1  Negative\n",
      "\n",
      "[100000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset with cleaned and preprocessed text \n",
    "\n",
    "# Define sentiment threshold values\n",
    "positive_threshold = 4.0  # Example threshold for positive sentiment\n",
    "neutral_threshold_low = 2.0  # Example lower threshold for neutral sentiment\n",
    "neutral_threshold_high = 4.0  # Example upper threshold for neutral sentiment\n",
    "\n",
    "# Define a mapping between ratings and sentiment labels\n",
    "def classify_sentiment(predicted_rating):\n",
    "    if predicted_rating >= positive_threshold:\n",
    "        return \"Positive\"\n",
    "    elif predicted_rating >= neutral_threshold_low and predicted_rating < neutral_threshold_high:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "# Apply the mapping function to create a new 'sentiment' column\n",
    "df['sentiment'] = df['rating'].apply(classify_sentiment)\n",
    "\n",
    "# Display the resulting DataFrame with sentiment labels\n",
    "print(df[['rating', 'sentiment']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "36a2c8ee-27eb-4549-aaeb-a7d846ab1b6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>16074</td>\n",
       "      <td>3</td>\n",
       "      <td>Comfortable, but not durable.</td>\n",
       "      <td>2022/11/07 05:30</td>\n",
       "      <td>comfortable but not durable</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>436</td>\n",
       "      <td>11648</td>\n",
       "      <td>4</td>\n",
       "      <td>Highly recommend!</td>\n",
       "      <td>2021/09/11 02:53</td>\n",
       "      <td>highly recommend</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>861</td>\n",
       "      <td>46508</td>\n",
       "      <td>2</td>\n",
       "      <td>Do not recommend.</td>\n",
       "      <td>2022/12/14 13:24</td>\n",
       "      <td>do not recommend</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>271</td>\n",
       "      <td>40094</td>\n",
       "      <td>3</td>\n",
       "      <td>Comfortable, but not durable.</td>\n",
       "      <td>2021/11/29 04:01</td>\n",
       "      <td>comfortable but not durable</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>49897</td>\n",
       "      <td>4</td>\n",
       "      <td>Will buy again.</td>\n",
       "      <td>2023/04/24 12:12</td>\n",
       "      <td>will buy again</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  product_id  user_id  rating                    review_text  \\\n",
       "0          1         103    16074       3  Comfortable, but not durable.   \n",
       "1          2         436    11648       4              Highly recommend!   \n",
       "2          3         861    46508       2              Do not recommend.   \n",
       "3          4         271    40094       3  Comfortable, but not durable.   \n",
       "4          5         107    49897       4                Will buy again.   \n",
       "\n",
       "          timestamp          cleaned_review_text sentiment  \n",
       "0  2022/11/07 05:30  comfortable but not durable   Neutral  \n",
       "1  2021/09/11 02:53             highly recommend  Positive  \n",
       "2  2022/12/14 13:24             do not recommend   Neutral  \n",
       "3  2021/11/29 04:01  comfortable but not durable   Neutral  \n",
       "4  2023/04/24 12:12               will buy again  Positive  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353244ba-a544-4afe-b65c-6c357a7612d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1e4ab3a-548f-4051-ad33-f708e3bfab58",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e3ed4629-6320-4134-89a0-53dae25a1b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the features (X) and the target (y)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=20) \n",
    "X = tfidf_vectorizer.fit_transform(df['cleaned_review_text'])\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split the dataset into training and testing sets (e.g., 80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the sizes of the training and testing sets\n",
    "#print(f\"Training set size: {len(X_train)}\")\n",
    "#print(f\"Testing set size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a03446e9-1123-4589-9fcd-1eb2efa18cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.51      0.40      0.45      4047\n",
      "     Neutral       0.72      0.80      0.76      7928\n",
      "    Positive       1.00      1.00      1.00      8025\n",
      "\n",
      "    accuracy                           0.80     20000\n",
      "   macro avg       0.74      0.73      0.74     20000\n",
      "weighted avg       0.79      0.80      0.79     20000\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize and train a Logistic Regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "#y_pred2 = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "report = classification_report(y_test, y_pred)\n",
    "#report1 = classification_report(y_test, y_pred2)\n",
    "print(report)\n",
    "print(\" \")\n",
    "#print(report1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9576ad-aa7e-4c40-9598-7c3dfdda74bc",
   "metadata": {},
   "source": [
    "- The above results show that our model performs well especially when it comes to the positive sentiments.\n",
    "- Overall scoring an 80% accuracy.\n",
    "- To obtain a better accuracy we have tried training another model (SVM) as seen below but obtain the same results. We can safely conclude that this is the optimal level of model we shall obtain and in order to obtain better performance metrics we will have to look at improving the train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab10cd09-33ed-4d69-9c1c-6dcdbd899ecb",
   "metadata": {},
   "source": [
    "### TESTING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f32e5bf6-f6fb-4bb8-8cb9-73da8f93ae4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_input= 'Poor shoe didnt even last!'\n",
    "user_input= [user_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "02fadb10-4eb4-49b2-b623-0a03fe642e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_input= 'Poor shoe didnt even last!'\n",
    "user_input= [user_input]\n",
    "for i in range(len(user_input)):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(user_input[i])\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    user_input[i] = ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3117de73-7b08-4773-801b-e619ccff6a71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poor shoe didnt even last']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "aaf9ac02-5d4e-4255-ac7f-9523e7f01a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_input_vectorized = tfidf_vectorizer.transform(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "433b432a-d486-4097-8651-7eedbf3efb2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_sentiment = classifier.predict(user_input_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3ea0ca6a-fa4a-4584-8a21-03a8e982a831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative'], dtype=object)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e25f4-6fc7-4e81-a49a-ae627137c032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bfa70-eef5-443a-9899-db0b53d253da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "27babf4e-99a1-4f4f-a65d-808fb44948c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_sentiment(predicted_ratings):\n",
    "    # Initialize an empty array to store the sentiment labels\n",
    "    sentiment_labels = []\n",
    "\n",
    "    # Iterate through each predicted rating\n",
    "    for rating in predicted_ratings:\n",
    "        if rating >= positive_threshold:\n",
    "            sentiment_labels.append(\"Positive\")\n",
    "        elif rating >= neutral_threshold_low and rating < neutral_threshold_high:\n",
    "            sentiment_labels.append(\"Neutral\")\n",
    "        else:\n",
    "            sentiment_labels.append(\"Negative\")\n",
    "\n",
    "    # Convert the list of sentiment labels to a NumPy array\n",
    "    sentiment_labels = np.array(sentiment_labels)\n",
    "\n",
    "    return sentiment_labels\n",
    "\n",
    "sentiment_classification = classify_sentiment(y_predR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7effb618-286c-49bd-84ce-ccf18af70418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive', 'Positive', ..., 'Neutral', 'Positive',\n",
       "       'Positive'], dtype='<U8')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "89fb12e5-1acf-451c-a868-73cf0b656d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "usertxt= 'Not a good product!'\n",
    "usertxt= preprocess_text(usertxt)\n",
    "usertxt = tfidf_vectorizer.fit_transform([usertxt])\n",
    "pred = regressor.predict(user_input_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553d940-5879-411e-a51c-591b88e4bfd2",
   "metadata": {},
   "source": [
    "## Trying different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "92d8ef00-1d8e-4e92-b66c-a52f0ab5a495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /users/gary/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /users/gary/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /users/gary/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (100000, 6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.51      0.40      0.45      4047\n",
      "     Neutral       0.72      0.80      0.76      7928\n",
      "    Positive       1.00      1.00      1.00      8025\n",
      "\n",
      "    accuracy                           0.80     20000\n",
      "   macro avg       0.74      0.73      0.74     20000\n",
      "weighted avg       0.79      0.80      0.79     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC  # Import the Support Vector Machine classifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('sneakers_Reviews_Dataset.csv', sep=\";\")\n",
    "print('Shape:', df.shape)\n",
    "df.head()\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "df['cleaned_review_text'] = df['review_text'].apply(preprocess_text)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=20)\n",
    "\n",
    "# Fit and transform the cleaned review_text\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['cleaned_review_text'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a Pandas DataFrame\n",
    "numeric_review = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Define sentiment threshold values\n",
    "positive_threshold = 4.0\n",
    "neutral_threshold_low = 2.0\n",
    "neutral_threshold_high = 4.0\n",
    "\n",
    "# Define a mapping between ratings and sentiment labels\n",
    "def classify_sentiment(predicted_rating):\n",
    "    if predicted_rating >= positive_threshold:\n",
    "        return \"Positive\"\n",
    "    elif predicted_rating >= neutral_threshold_low and predicted_rating < neutral_threshold_high:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "df['sentiment'] = df['rating'].apply(classify_sentiment)\n",
    "\n",
    "# Define the features (X) and the target (y)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=20)\n",
    "X = tfidf_vectorizer.fit_transform(df['cleaned_review_text'])\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split the dataset into training and testing sets (e.g., 80% for training, 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a Support Vector Machine (SVM) classifier\n",
    "model = SVC(kernel='linear', C=1.0)  # You can adjust the kernel and C parameter as needed\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred3 = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "report = classification_report(y_test, y_pred3)\n",
    "print(report)\n",
    "\n",
    "# Save the SVM model and TF-IDF vectorizer\n",
    "with open('sentiment_svm_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(classifier, model_file)\n",
    "\n",
    "with open('transformvec.pkl', 'wb') as transformvec_file:\n",
    "    pickle.dump(tfidf_vectorizer, transformvec_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "48ce037e-baa8-4a3b-9d13-c70a50347864",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.51      0.40      0.45      4047\n",
      "     Neutral       0.72      0.80      0.76      7928\n",
      "    Positive       1.00      1.00      1.00      8025\n",
      "\n",
      "    accuracy                           0.80     20000\n",
      "   macro avg       0.74      0.73      0.74     20000\n",
      "weighted avg       0.79      0.80      0.79     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train a Support Vector Machine (SVM) classifier\n",
    "model = SVC(kernel='poly', C=1.0)  # You can adjust the kernel and C parameter as needed\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred3 = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "report = classification_report(y_test, y_pred3)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "bb9d2d9e-b6ce-4228-a02a-8b77f28e05d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=  29.0s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=  28.9s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=  28.8s\n",
      "[CV] END ..................................C=0.1, kernel=rbf; total time=  41.5s\n",
      "[CV] END ..................................C=0.1, kernel=rbf; total time=  41.6s\n",
      "[CV] END ..................................C=0.1, kernel=rbf; total time=  41.6s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=  31.5s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=  31.6s\n",
      "[CV] END .................................C=0.1, kernel=poly; total time=  32.1s\n",
      "[CV] END .................................C=1, kernel=linear; total time=  28.1s\n",
      "[CV] END .................................C=1, kernel=linear; total time=  28.0s\n",
      "[CV] END .................................C=1, kernel=linear; total time=  28.1s\n",
      "[CV] END ....................................C=1, kernel=rbf; total time=  40.7s\n",
      "[CV] END ....................................C=1, kernel=rbf; total time=  41.1s\n",
      "[CV] END ....................................C=1, kernel=rbf; total time=  41.1s\n",
      "[CV] END ...................................C=1, kernel=poly; total time=  31.1s\n",
      "[CV] END ...................................C=1, kernel=poly; total time=  31.3s\n",
      "[CV] END ...................................C=1, kernel=poly; total time=  31.5s\n",
      "[CV] END ................................C=10, kernel=linear; total time=  28.1s\n",
      "[CV] END ................................C=10, kernel=linear; total time=  28.0s\n",
      "[CV] END ................................C=10, kernel=linear; total time=  28.0s\n",
      "[CV] END ...................................C=10, kernel=rbf; total time=  41.0s\n",
      "[CV] END ...................................C=10, kernel=rbf; total time=  41.2s\n",
      "[CV] END ...................................C=10, kernel=rbf; total time=  41.5s\n",
      "[CV] END ..................................C=10, kernel=poly; total time=  31.4s\n",
      "[CV] END ..................................C=10, kernel=poly; total time=  31.4s\n",
      "[CV] END ..................................C=10, kernel=poly; total time=  31.4s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.51      0.40      0.45      4047\n",
      "     Neutral       0.72      0.80      0.76      7928\n",
      "    Positive       1.00      1.00      1.00      8025\n",
      "\n",
      "    accuracy                           0.80     20000\n",
      "   macro avg       0.74      0.73      0.74     20000\n",
      "weighted avg       0.79      0.80      0.79     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search for Hyperparameter Tuning\n",
    "param_grid = {'C': [0.1, 1, 10],\n",
    "              'kernel': ['linear', 'rbf', 'poly']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred4 = best_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model's performance\n",
    "report3 = classification_report(y_test, y_pred4)\n",
    "print(report3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78826c2-e6ee-4a11-97c4-4c0e7f5230d5",
   "metadata": {},
   "source": [
    "- Overall we see that we obtained identical results for all 3 models, therefore any model shall do. We will use the Logistic Regression model for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d765c-0420-4795-90f3-c83cc475c700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b1b6b-0f84-477e-b248-1113f1639ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASTRO-GPU (TensorFlow)",
   "language": "python",
   "name": "astro-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
